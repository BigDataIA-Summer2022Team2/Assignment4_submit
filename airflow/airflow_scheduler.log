nohup: ignoring input
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[[34m2022-07-30 09:20:40,805[0m] {[34mscheduler_job.py:[0m708} INFO[0m - Starting the scheduler[0m
[[34m2022-07-30 09:20:40,806[0m] {[34mscheduler_job.py:[0m713} INFO[0m - Processing each file at most -1 times[0m
[[34m2022-07-30 09:20:40,814[0m] {[34mexecutor_loader.py:[0m105} INFO[0m - Loaded executor: SequentialExecutor[0m
[2022-07-30 09:20:40 +0100] [3172943] [INFO] Starting gunicorn 20.1.0
[[34m2022-07-30 09:20:40,825[0m] {[34mmanager.py:[0m160} INFO[0m - Launched DagFileProcessorManager with pid: 3172944[0m
[[34m2022-07-30 09:20:40,829[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[2022-07-30 09:20:40 +0100] [3172943] [INFO] Listening at: http://0.0.0.0:8793 (3172943)
[2022-07-30 09:20:40 +0100] [3172943] [INFO] Using worker: sync
[[34m2022-07-30 09:20:40,837[0m] {[34msettings.py:[0m55} INFO[0m - Configured default timezone Timezone('UTC')[0m
[2022-07-30 09:20:40 +0100] [3172945] [INFO] Booting worker with pid: 3172945
[2022-07-30 09:20:40 +0100] [3172946] [INFO] Booting worker with pid: 3172946
[2022-07-30 09:20:40,871] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[[34m2022-07-30 09:20:41,266[0m] {[34mdagrun.py:[0m549} ERROR[0m - Marking run <DagRun my_dag @ 2022-07-30 07:41:38+00:00: manual__2022-07-30T07:41:38+00:00, externally triggered: True> failed[0m
[[34m2022-07-30 09:20:41,267[0m] {[34mdagrun.py:[0m609} INFO[0m - DagRun Finished: dag_id=my_dag, execution_date=2022-07-30 07:41:38+00:00, run_id=manual__2022-07-30T07:41:38+00:00, run_start_date=2022-07-30 07:41:39.771256+00:00, run_end_date=2022-07-30 08:20:41.267736+00:00, run_duration=2341.49648, state=failed, external_trigger=True, run_type=manual, data_interval_start=2022-07-29 00:00:00+00:00, data_interval_end=2022-07-30 00:00:00+00:00, dag_hash=4242d703db81561ad8f16de1c6255127[0m
[[34m2022-07-30 09:20:41,276[0m] {[34mdag.py:[0m2968} INFO[0m - Setting next_dagrun for my_dag to 2022-07-30T00:00:00+00:00, run_after=2022-07-31T00:00:00+00:00[0m
[[34m2022-07-30 09:20:41,319[0m] {[34mscheduler_job.py:[0m353} INFO[0m - 1 tasks up for execution:
	<TaskInstance: my_dag.dataperf manual__2022-07-30T07:43:13+00:00 [scheduled]>[0m
[[34m2022-07-30 09:20:41,320[0m] {[34mscheduler_job.py:[0m418} INFO[0m - DAG my_dag has 0/16 running and queued tasks[0m
[[34m2022-07-30 09:20:41,320[0m] {[34mscheduler_job.py:[0m504} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_dag.dataperf manual__2022-07-30T07:43:13+00:00 [scheduled]>[0m
[[34m2022-07-30 09:20:41,328[0m] {[34mscheduler_job.py:[0m546} INFO[0m - Sending TaskInstanceKey(dag_id='my_dag', task_id='dataperf', run_id='manual__2022-07-30T07:43:13+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2022-07-30 09:20:41,328[0m] {[34mbase_executor.py:[0m91} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_dag', 'dataperf', 'manual__2022-07-30T07:43:13+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-30 09:20:41,333[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_dag', 'dataperf', 'manual__2022-07-30T07:43:13+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-30 09:20:43,022[0m] {[34mdagbag.py:[0m508} INFO[0m - Filling up the DagBag from /root/airflow/dags/mydag.py[0m
[[34m2022-07-30 09:20:43,115[0m] {[34mtask_command.py:[0m371} INFO[0m - Running <TaskInstance: my_dag.dataperf manual__2022-07-30T07:43:13+00:00 [queued]> on host racknerd-7bc619[0m
[[34m2022-07-30 09:21:49,419[0m] {[34mscheduler_job.py:[0m599} INFO[0m - Executor reports execution of my_dag.dataperf run_id=manual__2022-07-30T07:43:13+00:00 exited with status success for try_number 1[0m
[[34m2022-07-30 09:21:49,459[0m] {[34mscheduler_job.py:[0m642} INFO[0m - TaskInstance Finished: dag_id=my_dag, task_id=dataperf, run_id=manual__2022-07-30T07:43:13+00:00, map_index=-1, run_start_date=2022-07-30 08:20:43.172930+00:00, run_end_date=2022-07-30 08:21:44.006511+00:00, run_duration=60.833581, state=failed, executor_state=success, try_number=1, max_tries=0, job_id=34, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2022-07-30 08:20:41.322090+00:00, queued_by_job_id=33, pid=3172952[0m
[[34m2022-07-30 09:21:49,472[0m] {[34mmanager.py:[0m299} ERROR[0m - DagFileProcessorManager (PID=3172944) last sent a heartbeat 68.32 seconds ago! Restarting it[0m
[[34m2022-07-30 09:21:49,486[0m] {[34mprocess_utils.py:[0m125} INFO[0m - Sending Signals.SIGTERM to group 3172944. PIDs of all processes in the group: [3172944][0m
[[34m2022-07-30 09:21:49,486[0m] {[34mprocess_utils.py:[0m80} INFO[0m - Sending the signal Signals.SIGTERM to group 3172944[0m
[[34m2022-07-30 09:21:49,821[0m] {[34mprocess_utils.py:[0m75} INFO[0m - Process psutil.Process(pid=3172944, status='terminated', exitcode=0, started='09:20:40') (3172944) terminated with exit code 0[0m
[[34m2022-07-30 09:21:49,834[0m] {[34mmanager.py:[0m160} INFO[0m - Launched DagFileProcessorManager with pid: 3173423[0m
[[34m2022-07-30 09:21:49,849[0m] {[34msettings.py:[0m55} INFO[0m - Configured default timezone Timezone('UTC')[0m
[2022-07-30 09:21:49,879] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[[34m2022-07-30 09:21:50,175[0m] {[34mdagrun.py:[0m549} ERROR[0m - Marking run <DagRun my_dag @ 2022-07-30 07:43:13+00:00: manual__2022-07-30T07:43:13+00:00, externally triggered: True> failed[0m
[[34m2022-07-30 09:21:50,176[0m] {[34mdagrun.py:[0m609} INFO[0m - DagRun Finished: dag_id=my_dag, execution_date=2022-07-30 07:43:13+00:00, run_id=manual__2022-07-30T07:43:13+00:00, run_start_date=2022-07-30 08:20:41.206373+00:00, run_end_date=2022-07-30 08:21:50.175994+00:00, run_duration=68.969621, state=failed, external_trigger=True, run_type=manual, data_interval_start=2022-07-29 00:00:00+00:00, data_interval_end=2022-07-30 00:00:00+00:00, dag_hash=4242d703db81561ad8f16de1c6255127[0m
[[34m2022-07-30 09:21:50,182[0m] {[34mdag.py:[0m2968} INFO[0m - Setting next_dagrun for my_dag to 2022-07-30T00:00:00+00:00, run_after=2022-07-31T00:00:00+00:00[0m
[[34m2022-07-30 09:25:40,906[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-30 09:27:13,483[0m] {[34mscheduler_job.py:[0m353} INFO[0m - 1 tasks up for execution:
	<TaskInstance: my_dag.dataperf manual__2022-07-30T08:27:12.766120+00:00 [scheduled]>[0m
[[34m2022-07-30 09:27:13,485[0m] {[34mscheduler_job.py:[0m418} INFO[0m - DAG my_dag has 0/16 running and queued tasks[0m
[[34m2022-07-30 09:27:13,485[0m] {[34mscheduler_job.py:[0m504} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_dag.dataperf manual__2022-07-30T08:27:12.766120+00:00 [scheduled]>[0m
[[34m2022-07-30 09:27:13,500[0m] {[34mscheduler_job.py:[0m546} INFO[0m - Sending TaskInstanceKey(dag_id='my_dag', task_id='dataperf', run_id='manual__2022-07-30T08:27:12.766120+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2022-07-30 09:27:13,501[0m] {[34mbase_executor.py:[0m91} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_dag', 'dataperf', 'manual__2022-07-30T08:27:12.766120+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-30 09:27:13,505[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_dag', 'dataperf', 'manual__2022-07-30T08:27:12.766120+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-30 09:27:15,247[0m] {[34mdagbag.py:[0m508} INFO[0m - Filling up the DagBag from /root/airflow/dags/mydag.py[0m
[[34m2022-07-30 09:27:15,422[0m] {[34mtask_command.py:[0m371} INFO[0m - Running <TaskInstance: my_dag.dataperf manual__2022-07-30T08:27:12.766120+00:00 [queued]> on host racknerd-7bc619[0m
[[34m2022-07-30 09:27:41,418[0m] {[34mscheduler_job.py:[0m599} INFO[0m - Executor reports execution of my_dag.dataperf run_id=manual__2022-07-30T08:27:12.766120+00:00 exited with status success for try_number 1[0m
[[34m2022-07-30 09:27:41,449[0m] {[34mscheduler_job.py:[0m642} INFO[0m - TaskInstance Finished: dag_id=my_dag, task_id=dataperf, run_id=manual__2022-07-30T08:27:12.766120+00:00, map_index=-1, run_start_date=2022-07-30 08:27:15.497148+00:00, run_end_date=2022-07-30 08:27:38.581563+00:00, run_duration=23.084415, state=failed, executor_state=success, try_number=1, max_tries=0, job_id=35, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2022-07-30 08:27:13.486547+00:00, queued_by_job_id=33, pid=3174383[0m
[[34m2022-07-30 09:27:41,851[0m] {[34mdagrun.py:[0m549} ERROR[0m - Marking run <DagRun my_dag @ 2022-07-30 08:27:12.766120+00:00: manual__2022-07-30T08:27:12.766120+00:00, externally triggered: True> failed[0m
[[34m2022-07-30 09:27:41,851[0m] {[34mdagrun.py:[0m609} INFO[0m - DagRun Finished: dag_id=my_dag, execution_date=2022-07-30 08:27:12.766120+00:00, run_id=manual__2022-07-30T08:27:12.766120+00:00, run_start_date=2022-07-30 08:27:13.410390+00:00, run_end_date=2022-07-30 08:27:41.851763+00:00, run_duration=28.441373, state=failed, external_trigger=True, run_type=manual, data_interval_start=2022-07-29 00:00:00+00:00, data_interval_end=2022-07-30 00:00:00+00:00, dag_hash=4242d703db81561ad8f16de1c6255127[0m
[[34m2022-07-30 09:27:41,858[0m] {[34mdag.py:[0m2968} INFO[0m - Setting next_dagrun for my_dag to 2022-07-30T00:00:00+00:00, run_after=2022-07-31T00:00:00+00:00[0m
[[34m2022-07-30 09:30:40,951[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-30 09:35:40,995[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-30 09:40:41,054[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-30 09:43:26,304[0m] {[34mscheduler_job.py:[0m353} INFO[0m - 1 tasks up for execution:
	<TaskInstance: my_dag.dataperf manual__2022-07-30T08:43:25+00:00 [scheduled]>[0m
[[34m2022-07-30 09:43:26,305[0m] {[34mscheduler_job.py:[0m418} INFO[0m - DAG my_dag has 0/16 running and queued tasks[0m
[[34m2022-07-30 09:43:26,305[0m] {[34mscheduler_job.py:[0m504} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: my_dag.dataperf manual__2022-07-30T08:43:25+00:00 [scheduled]>[0m
[[34m2022-07-30 09:43:26,309[0m] {[34mscheduler_job.py:[0m546} INFO[0m - Sending TaskInstanceKey(dag_id='my_dag', task_id='dataperf', run_id='manual__2022-07-30T08:43:25+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2022-07-30 09:43:26,309[0m] {[34mbase_executor.py:[0m91} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'my_dag', 'dataperf', 'manual__2022-07-30T08:43:25+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-30 09:43:26,312[0m] {[34msequential_executor.py:[0m59} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'my_dag', 'dataperf', 'manual__2022-07-30T08:43:25+00:00', '--local', '--subdir', 'DAGS_FOLDER/mydag.py'][0m
[[34m2022-07-30 09:43:27,932[0m] {[34mdagbag.py:[0m508} INFO[0m - Filling up the DagBag from /root/airflow/dags/mydag.py[0m
[[34m2022-07-30 09:43:28,053[0m] {[34mtask_command.py:[0m371} INFO[0m - Running <TaskInstance: my_dag.dataperf manual__2022-07-30T08:43:25+00:00 [queued]> on host racknerd-7bc619[0m
[[34m2022-07-30 09:43:43,858[0m] {[34mscheduler_job.py:[0m599} INFO[0m - Executor reports execution of my_dag.dataperf run_id=manual__2022-07-30T08:43:25+00:00 exited with status success for try_number 1[0m
[[34m2022-07-30 09:43:43,893[0m] {[34mscheduler_job.py:[0m642} INFO[0m - TaskInstance Finished: dag_id=my_dag, task_id=dataperf, run_id=manual__2022-07-30T08:43:25+00:00, map_index=-1, run_start_date=2022-07-30 08:43:28.109530+00:00, run_end_date=2022-07-30 08:43:41.398229+00:00, run_duration=13.288699, state=failed, executor_state=success, try_number=1, max_tries=0, job_id=36, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2022-07-30 08:43:26.306593+00:00, queued_by_job_id=33, pid=3175983[0m
[[34m2022-07-30 09:43:44,002[0m] {[34mdagrun.py:[0m549} ERROR[0m - Marking run <DagRun my_dag @ 2022-07-30 08:43:25+00:00: manual__2022-07-30T08:43:25+00:00, externally triggered: True> failed[0m
[[34m2022-07-30 09:43:44,003[0m] {[34mdagrun.py:[0m609} INFO[0m - DagRun Finished: dag_id=my_dag, execution_date=2022-07-30 08:43:25+00:00, run_id=manual__2022-07-30T08:43:25+00:00, run_start_date=2022-07-30 08:43:26.248324+00:00, run_end_date=2022-07-30 08:43:44.002902+00:00, run_duration=17.754578, state=failed, external_trigger=True, run_type=manual, data_interval_start=2022-07-29 00:00:00+00:00, data_interval_end=2022-07-30 00:00:00+00:00, dag_hash=4242d703db81561ad8f16de1c6255127[0m
[[34m2022-07-30 09:43:44,012[0m] {[34mdag.py:[0m2968} INFO[0m - Setting next_dagrun for my_dag to 2022-07-30T00:00:00+00:00, run_after=2022-07-31T00:00:00+00:00[0m
[[34m2022-07-30 09:45:41,109[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-30 09:50:41,159[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-30 09:55:41,206[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-30 10:00:41,297[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-30 10:05:41,357[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-30 10:10:41,427[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2022-07-30 10:15:41,478[0m] {[34mscheduler_job.py:[0m1233} INFO[0m - Resetting orphaned tasks for active dag runs[0m
